import json
import os
import re
from typing import List
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from google.generativeai import GenerativeModel, configure


# === Gemini LLM Wrapper ===
class GeminiLLM:
    def __init__(self, model="gemini-2.5-flash", api_key=None):
        configure(api_key=api_key or os.getenv("AIzaSyBzVdrsbkQL7qXmcSZNbVs8kN7jyVfqzF0"))
        self.model = GenerativeModel(model)

    def invoke(self, prompt: str) -> str:
        print("üìù Prompt Sent:\n", prompt)
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print("‚úó Gemini error:", e)
            return "Error: Cannot generate response."


# === Dataset Answerer ===
class DatasetAnswerer:
    def __init__(self, dataset_path="filtered_output.json", llm=None):
        self.llm = llm
        with open(dataset_path, "r", encoding="utf-8") as f:
            self.data = json.load(f)

        self.questions = [item["question"] for item in self.data]
        self.vectorizer = TfidfVectorizer().fit(self.questions)
        self.embeddings = self.vectorizer.transform(self.questions)

    def find_similar_context(self, query, top_n=3):
        query_vec = self.vectorizer.transform([query])
        scores = cosine_similarity(query_vec, self.embeddings)[0]
        top_idx = scores.argsort()[::-1][:top_n]
        return [self.data[i] for i in top_idx]

    def answer(self, user_question: str) -> str:
        context_items = self.find_similar_context(user_question)
        context_text = "\n".join(
            [f"Q: {item['question']}\nA: {item['answer']}" for item in context_items]
        )

        prompt = f"""
You are an AI that can only answer based on the provided datase.

Now answer this question:
{user_question}

If the answer is not in the dataset, say "Not found in dataset."
"""
        return self.llm.invoke(prompt)


# === Example Usage ===
if __name__ == "__main__":
    # üõ† Replace with your actual Gemini API Key
    GEMINI_API_KEY = "AIzaSyBzVdrsbkQL7qXmcSZNbVs8kN7jyVfqzF0"

    # ‚úÖ Create LLM instance
    llm = GeminiLLM(api_key=GEMINI_API_KEY)

    # ‚úÖ Create dataset answerer
    answerer = DatasetAnswerer(dataset_path="filtered_output.json", llm=llm)

    # üß™ Ask new questions
    questions = [
        "‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á",
        "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ï‡∏£‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£",
        "‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πà‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?",
        "‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ü‡∏≠‡∏Å‡πÄ‡∏á‡∏¥‡∏ô (AML)",
        "‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ DTI (Debt-to-Income Ratio) ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
        "‡∏ò‡∏õ‡∏ó.‡∏°‡∏µ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏¢‡∏±‡∏á‡πÑ‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•"
    ]

    for q in questions:
        print(f"\n‚ùì Question: {q}")
        print("‚úÖ Answer:", answerer.answer(q))
        print("-" * 60)
